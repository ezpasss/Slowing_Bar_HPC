# Slowing_Bar_HPC
Slowing Bar Integration for HPC
This program integrates a numpy array (.npy file) of cylindrical cords, returning 3 numpy arrays of cylindrical, cartesian, and action potential values. 
### THIS PROGRAM MUST BE RUN ON A HPC ###
# Instructions
To run this program first open terminal 
1. ssh USERNAME@hpc.arizona
2. Navigate to where you want to download the program. Using cd to navigate.
3. In the terminal enter: git clone https://github.com/ezpasss/Slowing_Bar_HPC.git
Once this is completed the Slowing Bar Integration is downloaded.
# Running the program
Use cd to navigate into the parent directory --> cd Slowing_Bar_HPC/
Once here, move the input file into the !_Input folder.
The files can be moved in two ways. 
  Using the HPC OnDemand
  1. Using the HPC OnDemand navigate to the !_Input folder and click upload.
  2. Either drag the input npy file to the submission box or browse your files and select it.
  Using the file transfer system. 
  1. USING A SEPARATE TERMINAL first navigate to the local directory where the input file is located.
  2. Connecting to the HPC's file transfer service in the terminal using --> sftp USERNAME@filexfer.hpc.arizona.edu
  3. You are now on the HPC, navigate to the !_Input folder using cd in the terminal.
  4. In Terminal use put (FILENAME)
## Modifying the program for your use
For the program to run properly you must modify some lines in slowing_bar_run_hpc.sh
This can be achieved using the HPC's OnDemand or through the terminal. 
  # Through Terminal
  1.   Navigate to the program's parent directory.
  2.   In the terminal enter nano slowing_bar_run_hpc.sh
  3.   If you want to change the number of CPUs per node modify line --> #SBATCH --cpus-per-task=5 --> Change 5 to how many cpus per node
  4.   If you would like to change the number of nodes used modify line --> #SBATCH --array=0-3 --> The number of nodes is equal to the second number plus 1 (so 0-3 is 4 nodes) THE NUMBER OF CPU'S USED IS NODES*CPUS_PER_NODE (4*5=20)
  5.   **MUST DO** To set the location for output logs modify line --> #SBATCH --output=/home/u(ENTERYOURNUMBER)/USERNAME/job_outputs/slowing_bar/job_out_%x-%j-%A-%a.out --> Input your username and u#
     a. This example puts the output files into a slowing_bar folder inside of a job_outputs folder located in the parent directory for a local account. You may change this to wherever you would like your job reports to go. **These files contain the job reports for each array. They do not contain the orbit data. They are exclusively reports generated by the HPC to track job progress.**
  6.   **MUST DO** To set the email where job notifications will be sent change --> #SBATCH --mail-user=USERNAME@arizona.edu --> To your username
  7.   **MUST DO** To set how many stars you would like to integrate modify line --> number_of_starts_to_integrate=20 --> Enter the number of stars you would like to integrate here or enter -1 to use the whole array.
  8.   **MUST DO** If you changed the number of arrays you are integrating **YOU MUST CHANGE THIS LINE TO THE APPROPRIATE NUMBER OF NODES** --> tot_arr=4 # this is the total number of jobs --> You must set this to the correct number of nodes or the program **will not run properly**
  9.   To submit your changes use ctrl+o and then enter to save your changes. Then use ctrl+x to exit
  # Through the HPC's OnDemand using VSCode
  1. On the HPC OnDemand website navigate to the Apps dropdown in the top left corner.
  2. Click on VsCode and scroll down to the bottom and click launch
  3. Once the session starts click on the Launch VsCode Gui button.
  4. In the top left click on file and then click on open file
  5. Navigate to the Slowing_Bar_HPC folder and select slowing_bar_run_hpc.sh
  6. If you want to change the number of CPUs per node modify line --> #SBATCH --cpus-per-task=5 --> Change 5 to how many cpus per node
  7. If you would like to change the number of nodes used modify line --> #SBATCH --array=0-3 --> The number of nodes is equal to the second number plus 1 (so 0-3 is 4 nodes) THE NUMBER OF CPU'S USED IS NODES*CPUS_PER_NODE (4*5=20)
  8. **MUST DO** To set the location for output logs modify line --> #SBATCH --output=/home/u(ENTERYOURNUMBER)/USERNAME/job_outputs/slowing_bar/job_out_%x-%j-%A-%a.out --> Input your username and u#
     a. This example puts the output files into a slowing_bar folder inside of a job_outputs folder located in the parent directory for a local account. You may change this to wherever you would like your job reports to go. **These files contain the job reports for each array. They do not contain the orbit data. They are exclusively reports generated by the HPC to track job progress.**
  9. **MUST DO** To set the email where job notifications will be sent change --> #SBATCH --mail-user=USERNAME@arizona.edu --> To your username
  10. **MUST DO** To set how many stars you would like to integrate modify line --> number_of_starts_to_integrate=20 --> Enter the number of stars you would like to integrate here or enter -1 to use the whole array.
  11. **MUST DO** If you changed the number of arrays you are integrating **YOU MUST CHANGE THIS LINE TO THE APPROPRIATE NUMBER OF NODES** --> tot_arr=4 # this is the total number of jobs --> You must set this to the correct number of nodes or the program **will not run properly**
  12. Exit out of the VsCode Gui and close the session.
